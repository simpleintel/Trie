{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trie Implementation for searching terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This will be tree implementation\n",
    "A not with a list of children\n",
    "\n",
    "\"\"\"\n",
    "class TrieNode(object):\n",
    "    def __init__(self, terms):\n",
    "        self.term = terms\n",
    "        self.children = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add a new element into trie data structure. Each of the terms comes into the trie, and checked if already exist. A child node is selected if it already exist and the remaining terms are added as children.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add(root, terms):\n",
    "    \"\"\"\n",
    "    Adding terms in the trie structure\n",
    "    \"\"\"\n",
    "    node = root\n",
    "    for term in terms:\n",
    "        found_in_child = False\n",
    "        for child in node.children:\n",
    "            if child.term == term:\n",
    "                node = child\n",
    "                found_in_child = True\n",
    "                break\n",
    "        if not found_in_child:\n",
    "            new_node = TrieNode(term)\n",
    "            node.children.append(new_node)\n",
    "            node = new_node\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# helper function for traction the location of words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texLocationTrack(track_more_than_one_terms, term_location_map, starting_index):\n",
    "    if(len(track_more_than_one_terms) == 0):\n",
    "        return\n",
    "    strAllString = ' '.join(track_more_than_one_terms)\n",
    "    if (strAllString in term_location_map):\n",
    "        term_location_map[strAllString].append(starting_index)\n",
    "    else:\n",
    "        term_location_map[strAllString] = []\n",
    "        term_location_map[strAllString].append(starting_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This functions takes the entire text and finds if the terms are present in the terms list using the trie. You can think of the text as a list of needed text seprated by unwanted texts. \n",
    "\n",
    "For example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text(root, text):\n",
    "    \"\"\"\n",
    "    Search for terms in the Trie\n",
    "    \"\"\"\n",
    "    node = root\n",
    "    if not root.children:\n",
    "        return False, 0\n",
    "    term_location_map = {}\n",
    "    track_more_than_one_terms = []\n",
    "    starting_index = -1\n",
    "    for i in range(len(text)):\n",
    "        found_term = False\n",
    "        for child in node.children:\n",
    "            if child.term == text[i]:\n",
    "                track_more_than_one_terms.append(text[i])\n",
    "                node = child\n",
    "                if(starting_index == -1):\n",
    "                    starting_index = i + 1\n",
    "                found_term = True\n",
    "                break\n",
    "        \"\"\"\n",
    "        Once a sequence of \n",
    "        \"\"\"\n",
    "        if (found_term == False):\n",
    "            texLocationTrack(track_more_than_one_terms, term_location_map, starting_index)\n",
    "            track_more_than_one_terms = []\n",
    "            starting_index = -1\n",
    "            node = root\n",
    "\n",
    "    \"\"\"\n",
    "    Adding terms in the trie structure\n",
    "    \"\"\"\n",
    "    if (found_term == True):\n",
    "        texLocationTrack(track_more_than_one_terms, term_location_map, starting_index)\n",
    "    return term_location_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Term Borrowerin Locations 5,20,32,39,46,78,96,104,126,144,152\n",
      "Found Term Subsidiariesin Locations 22,81,129\n",
      "Found Term Material Project Partyin Locations 51\n",
      "Found Term Projectin Locations 58\n",
      "Found Term Anti-Money Laundering Lawsin Locations 70,122\n",
      "Found Term Anti-Corruption Lawsin Locations 75,119\n",
      "Found Term Sanctioned Personin Locations 171\n",
      "Found Term Sanctioned Countryin Locations 178\n",
      "Found Term Sanctionsin Locations 187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text = 'The operations of each Borrower, and the activities of the officers and directors and, to the knowledge of each Borrower, any Subsidiaries of the Borrowers, employees, agents and representatives of each Borrower, while acting on behalf of such Borrower, and to the knowledge of each Borrower the operations of each Material Project Party in relation to the Project, have been conducted at all times in compliance with all applicable Anti-Money Laundering Laws, Sanctions, and Anti-Corruption Laws. Neither Borrower, nor any Subsidiaries of the Borrowers, nor any officer or director or, to the knowledge of any Borrower, Affiliates, employee, agent or representative of either Borrower has engaged, directly or indirectly, in any activity or conduct which would violate any Anti-Corruption Laws or Anti-Money Laundering Laws. Neither Borrower nor any Subsidiaries of the Borrowers, nor any officer or director or, to the knowledge of any Borrower, Affiliates, employee, agent or representative of either Borrower has engaged, directly or indirectly, in any dealings or transactions with, involving or for the benefit of a Sanctioned Person, or in or involving a Sanctioned Country, where such dealings or transactions would violate Sanctions, in the five (5) year periodimmediately preceding the date hereof.'\n",
    "    terms = ['Borrower', 'Subsidiaries', 'Material Project Party', 'Project', 'Project Manager',\n",
    "             'Anti-Money Laundering Laws', 'Sanctions', 'Anti-Corruption Laws', 'Affiliates', 'Sanctioned Person',\n",
    "             'Sanctioned Country', 'Person', 'Officer', 'Director', 'Agents']\n",
    "    # Removing the punctuations and tokenizing\n",
    "    text = regexp_tokenize(text, \"[\\w-]+\")\n",
    "    root = TrieNode('*')\n",
    "\n",
    "    for term in terms:\n",
    "        arrTerms =  term.split()\n",
    "        add(root, arrTerms)\n",
    "    locationOfTerms = find_text(root, text)\n",
    "    for k in locationOfTerms:\n",
    "        print(\"Found Term \" + k + \"in locations \" + ','.join(str(x) for x in locationOfTerms[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
